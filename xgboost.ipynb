{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste an möglichen Features:\n",
    "\n",
    "- start_x\n",
    "- start_y\n",
    "- end_x\n",
    "- end_y\n",
    "- time_seconds\t\t\n",
    "- type_name\t\n",
    "- bodypart_name\t\n",
    "- action_distance\n",
    "- shot_angle_centered\n",
    "- distance_to_goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target:\n",
    "- result_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import socceraction.spadl as spadl\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import brier_score_loss, log_loss, roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from interpret import show\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "from src.data_processing import config_h5_file_paths, split_games, load_match_data\n",
    "from src.vaep_processing import load_features_labels, train_model, evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_my_model(model, X, y):\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    # Brier Score: misst die durchschnittliche quadratische Differenz zwischen \n",
    "    # den vorhergesagten Wahrscheinlichkeiten und den tatsächlichen binären Ergebnissen.\n",
    "    brier = brier_score_loss(y, y_pred)\n",
    "    print(f\"Brier score: {brier:.5f}\")\n",
    "\n",
    "    # Log Loss: misst, wie gut die Wahrscheinlichkeiten die tatsächlichen Ergebnisse repräsentieren.\n",
    "    ll = log_loss(y, y_pred)\n",
    "    print(f\"log loss score: {ll:.5f}\")\n",
    "\n",
    "    # ROC AUC: misst die Fähigkeit des Modells, zwischen Klassen zu unterscheiden (0 vs. 1).\n",
    "    roc_auc = roc_auc_score(y, y_pred)\n",
    "    print(f\"ROC AUC: {roc_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '.\\xSuccess\\top5_15-16_spadl' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Configure format, h5-file, and folder names\n",
    "datafolder = \".\\\\xSuccess\\\\top5_15-16_spadl\"\n",
    "format = \"spadl\"\n",
    "\n",
    "match_data_h5, match_data_train_h5, match_data_test_h5, match_data_test_success_h5, match_data_test_fail_h5, features_train_h5, features_test_h5, features_test_success_h5, features_test_fail_h5, labels_train_h5, labels_test_h5, labels_test_success_h5, labels_test_fail_h5, predictions_test_h5, predictions_test_success_h5, predictions_test_fail_h5, vaep_test_h5, vaep_test_success_h5, vaep_test_fail_h5 = config_h5_file_paths(\n",
    "  datafolder=datafolder,\n",
    "  format=format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade den Datensatz\n",
    "spadl_h5 = \".\\\\xSuccess\\\\top5_15-16_spadl\\\\match_data.h5\"\n",
    "\n",
    "with pd.HDFStore(spadl_h5) as spadlstore:\n",
    "    # Spiele laden\n",
    "    games = spadlstore[\"games\"]\n",
    "    \n",
    "    # teams / players laden, wenn du sie für später brauchst\n",
    "    teams = spadlstore[\"teams\"]\n",
    "    players = spadlstore[\"players\"]\n",
    "    \n",
    "    all_actions_list = []\n",
    "    \n",
    "    # Über alle Spiele iterieren\n",
    "    for gid in games.game_id:\n",
    "        df_actions = spadlstore[f\"actions/game_{gid}\"]\n",
    "        # Ggf. noch die 'game_id' explizit als Spalte hinzufügen,\n",
    "        # falls du sie später brauchst.\n",
    "        df_actions[\"game_id\"] = gid\n",
    "        \n",
    "        all_actions_list.append(df_actions)\n",
    "    \n",
    "    # Zu einem großen DataFrame zusammenfügen\n",
    "    all_actions= pd.concat(all_actions_list, ignore_index=True)\n",
    "\n",
    "all_actions = (\n",
    "    all_actions\n",
    "    .merge(spadl.actiontypes_df(), how='left', on='type_id')\n",
    "    .merge(spadl.results_df(), how='left', on='result_id')\n",
    "    .merge(spadl.bodyparts_df(), how='left', on='bodypart_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result_id hat mehr als nur 0 und 1, darum werden alle auf 0 gesetzt die nicht 1 sind\n",
    "all_actions[\"result_id\"] = np.where(all_actions[\"result_id\"] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Länge der Dribblings (euklidische Distanz zwischen Start- und Endkoordinate)\n",
    "\n",
    "all_actions[\"action_distance\"] = np.sqrt(\n",
    "    (all_actions[\"end_x\"] - all_actions[\"start_x\"])**2 +\n",
    "    (all_actions[\"end_y\"] - all_actions[\"start_y\"])**2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winkel für Schüsse berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angenommen: Spielfeld geht von x=0 bis x=105 (Opta Standard)\n",
    "def detect_goal_side(end_x, field_length=105):\n",
    "    return 'left' if end_x < field_length / 2 else 'right'\n",
    "\n",
    "def calculate_centered_shot_angle(row):\n",
    "    # Ziel-Torposition\n",
    "    if row['goal_side'] == 'right':\n",
    "        goal_x, goal_y = 105, 34\n",
    "        dx = goal_x - row['start_x']\n",
    "    else:\n",
    "        goal_x, goal_y = 0, 34\n",
    "        dx = row['start_x'] - goal_x  # Richtung umdrehen!\n",
    "\n",
    "    dy = goal_y - row['start_y']\n",
    "\n",
    "    # Jetzt ist dx immer positiv → Richtung zum Tor ist einheitlich\n",
    "    angle_rad = np.arctan2(dy, dx)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte erstellen\n",
    "all_actions['shot_angle_centered'] = np.nan\n",
    "\n",
    "# Torseite erkennen (für alle Zeilen, nicht nur Schüsse)\n",
    "all_actions['goal_side'] = all_actions['start_x'].apply(detect_goal_side)\n",
    "\n",
    "# Winkel nur für Schüsse berechnen\n",
    "\n",
    "shot_mask = all_actions['type_name'] == 'shot'\n",
    "all_actions.loc[shot_mask, 'shot_angle_centered'] = all_actions[shot_mask].apply(calculate_centered_shot_angle, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distanz zum Tor nach Aktion berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Distanz zum Tor. Hier wird für jede Zeile abhängig von der goal_side der entsprechende Tor-X-Wert gewählt.\n",
    "\n",
    "all_actions[\"distance_to_goal\"] = np.sqrt(\n",
    "    (all_actions[\"end_x\"] - np.where(all_actions[\"goal_side\"] == \"right\", 105, 0))**2 +\n",
    "    (all_actions[\"end_y\"] - 34)**2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen der Unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions[\"unique_id\"] = all_actions[\"game_id\"].astype(str) + \"_\" + all_actions[\"action_id\"].astype(str)\n",
    "all_actions.fillna(999, inplace=True)\n",
    "all_actions.sort_values(by=\"unique_id\", ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufteilen der Daten in Training und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split games\n",
    "train_games, test_games, validation_games = split_games(\n",
    "  games=all_actions,\n",
    "  train_percentage=50,\n",
    "  random_state=42,\n",
    "  shuffle=True,\n",
    "  stratify='team_id'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features und die Zielvariable\n",
    "features = [\"start_x\", \n",
    "            \"start_y\", \n",
    "            \"end_x\", \n",
    "            \"end_y\",\n",
    "            \"player_id\", \n",
    "            \"bodypart_name\", \n",
    "            \"type_name\", \n",
    "            \"action_distance\",\n",
    "            'shot_angle_centered', \n",
    "            \"time_seconds\",\n",
    "            'distance_to_goal']\n",
    "#features = [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"bodypart_name\", \"type_name\", \"action_distance\",'shot_angle_centered', \"time_seconds\",'distance_to_goal']\n",
    "target = \"result_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_games[features]\n",
    "Y_train = train_games[target]\n",
    "\n",
    "X_test = test_games[features]\n",
    "Y_test = test_games[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.28505\n",
      "log loss score: 10.27413\n",
      "ROC AUC: 0.49979\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='stratified')\n",
    "dummy_model.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_my_model(dummy_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.25000\n",
      "log loss score: 0.69315\n",
      "ROC AUC: 0.50000\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='uniform')\n",
    "dummy_model.fit(X_train, Y_train)\n",
    "evaluate_my_model(dummy_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.17197\n",
      "log loss score: 6.19832\n",
      "ROC AUC: 0.50000\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent')\n",
    "dummy_model.fit(X_train, Y_train)\n",
    "evaluate_my_model(dummy_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xSuccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_games[features].copy()\n",
    "X_test  = test_games [features].copy()\n",
    "\n",
    "# Liste der Objekt-Spalten\n",
    "cat_cols = [\"bodypart_name\", \"type_name\",\"player_id\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_train[col] = X_train[col].astype(\"category\")\n",
    "    X_test [col] = X_test [col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.07202\n",
      "log loss score: 0.22661\n",
      "ROC AUC: 0.93423\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_jobs=-1,\n",
    "    enable_categorical=True,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_my_model(xgb_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpret.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train.copy()\n",
    "Y_train_full = Y_train.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liste der Objekt-Spalten\n",
    "cat_cols = [\"bodypart_name\", \"type_name\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_train_full.loc[:,col] = X_train_full[col].astype(\"category\")\n",
    "    X_test.loc[:, col] = X_test[col].astype(\"category\")\n",
    "\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "X_train_full.loc[:, num_cols] = X_train_full[num_cols].astype(\"float32\")\n",
    "X_test.loc[:,num_cols] = X_test[num_cols].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling, da das Training zu lange dauert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, Y_train, _ = train_test_split(\n",
    "    X_train_full, Y_train_full,\n",
    "    train_size=50000,      # exakte Anzahl oder als float für Prozent\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: in NumPy-Array umwandeln\n",
    "y_arr = Y_train.values\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(\n",
    "    n_jobs=-1,          # alle Kerne nutzen\n",
    "    random_state=42,    # für Reproduzierbarkeit\n",
    "    max_bins=32,       # weniger Splits = schneller\n",
    "    interactions=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.07665\n",
      "log loss score: 0.24165\n",
      "ROC AUC: 0.92733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ebm.fit(X_train, y_arr)\n",
    "\n",
    "evaluate_my_model(ebm, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_bins=16\n",
    "\n",
    "train_size=10000  == Brier score: 0.07678 \\\n",
    "train_size=20000  == Brier score: 0.07398 \\\n",
    "train_size=30000  == Brier score: 0.07424 \\\n",
    "train_size=40000  == Brier score: 0.07373 \\\n",
    "train_size=50000  == Brier score: 0.07350 \\\n",
    "train_size=60000  == Brier score: 0.07414 <Time: >\n",
    "\n",
    "\n",
    "max_bins=32\n",
    "\n",
    "train_size=10000  == Brier score: 0.07534 \\\n",
    "train_size=20000  == Brier score: 0.07337 \\\n",
    "train_size=30000  == Brier score: 0.07305 \\\n",
    "train_size=40000  == Brier score: 0.07271 \\\n",
    "train_size=50000  == Brier score: 0.07243 \\\n",
    "train_size=60000  == Brier score: 0.07261 <Time: 1m 6s>\n",
    "\n",
    "\n",
    "max_bins=64\n",
    "\n",
    "train_size=10000  == Brier score: 0.07513\\\n",
    "train_size=20000  == Brier score: 0.07329\\\n",
    "train_size=30000  == Brier score: 0.07300\\\n",
    "train_size=40000  == Brier score: 0.07267\\\n",
    "train_size=50000  == Brier score: 0.07244\\\n",
    "train_size=60000  == Brier score: 0.07228 <Time: 1m 3s>\n",
    "\n",
    "\n",
    "max_bins=128\n",
    "\n",
    "train_size=10000  == Brier score: 0.07435\\\n",
    "train_size=20000  == Brier score: 0.07246\\\n",
    "train_size=30000  == Brier score: 0.07204\\\n",
    "train_size=40000  == Brier score: 0.07173\\\n",
    "train_size=50000  == Brier score: 0.07145   <Time: 1m 7s>\\\n",
    "train_size=60000  == Brier score: 0.07134   <Time: 1m> \\\n",
    "train_size=100000  == Brier score: 0.07086  <Time: 2m 14s>\\\n",
    "train_size=200000  == Brier score: 0.07001  <Time: 6m 2s>\\\n",
    "train_size=300000  ==  <Time: >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelle speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models\\\\ebm_model.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ordner \"Models\" anlegen (wenn er noch nicht existiert)\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# Modelle in diesem Ordner speichern\n",
    "joblib.dump(dummy_model, os.path.join(\"Models\", \"dummy_model.joblib\"))\n",
    "joblib.dump(xgb_model,   os.path.join(\"Models\", \"xgb_model_with_player_id.joblib\"))\n",
    "joblib.dump(ebm,         os.path.join(\"Models\", \"ebm_model_with_player_id.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelle laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zum Models-Ordner\n",
    "models_dir = \"Models\"\n",
    "\n",
    "# Modelle laden\n",
    "dummy_model = joblib.load(os.path.join(models_dir, \"dummy_model.joblib\"))\n",
    "xgb_model   = joblib.load(os.path.join(models_dir, \"xgb_model.joblib\"))\n",
    "ebm         = joblib.load(os.path.join(models_dir, \"ebm_model.joblib\"))\n",
    "\n",
    "# prüfen, ob es geklappt hat\n",
    "print(type(dummy_model), type(xgb_model), type(ebm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/2345478371712/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/2345478371712/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "show(ebm.explain_global())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfussionsmatrix für beide Modelle zum auswerten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 zufällige Indizes aus dem Testset auswählen\n",
    "np.random.seed(42)  # für Reproduzierbarkeit\n",
    "sample_indices = np.random.choice(X_test.index, size=3, replace=False)\n",
    "\n",
    "# Beispiel-Daten auswählen\n",
    "X_sample = X_test.loc[sample_indices]\n",
    "Y_true_sample = Y_test.loc[sample_indices]\n",
    "\n",
    "# Vorhersagen von beiden Modellen\n",
    "Y_pred_xgb_sample = xgb_model.predict_proba(X_sample)[:-1]\n",
    "Y_pred_gam_sample = ebm.predict_proba(X_sample.values)[:-1]\n",
    "\n",
    "# Übersicht als Tabelle\n",
    "vergleich_df = pd.DataFrame({\n",
    "    \"True Label\": Y_true_sample.values,\n",
    "    \"XGBoost Prediction\": Y_pred_xgb_sample,\n",
    "    \"GAM Prediction\": Y_pred_gam_sample\n",
    "}, index=sample_indices)\n",
    "\n",
    "# Input-Features anhängen (optional)\n",
    "vergleich_df = pd.concat([X_sample.reset_index(drop=True), vergleich_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "print(tabulate(vergleich_df, headers='keys', tablefmt='github'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verteilung der Werte in result_id anzeigen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
